RNNs are a type of neural network where the whole network is used repeatedly over a sequence of data. They also have a form of memory where they are able to remember the earlier parts of the sequence.
This make them much better at dealing with sequencial data, although they have their drawbacks such as exploding / vanishing gradients.
Additionally, their memory is not perfect and they struggle with long sequences which led to the development of variants such as LSTM and GRU to deal with these problems.
